---
layout: single
title: "Research Projects"
permalink: /research/
author_profile: true
---

## ğŸ”¬ Research Projects

### ğŸ¤— Hugging Face Transformer Fine-tuning | Sep 2025  
- Explored **transfer learning** techniques with Hugging Face Transformers to adapt pre-trained models for Korean NLP tasks.  
- Fine-tuned **KoBERT, DistilBERT, and GPT-2** on custom Korean datasets, addressing both **emotion classification** and **dialogue generation**.  
- Experimented with multiple training strategies, including **Supervised Fine-tuning (SFT)**, **early stopping**, and **hyperparameter tuning**.  
- Evaluated model performance using accuracy and qualitative assessments of generated outputs.  
- Gained practical experience in **adapting large pre-trained models** to domain-specific tasks and comparing their effectiveness across architectures.  
- [ğŸ”— GitHub Repository](https://github.com/JeongMinIsBest/AIFFEL_quest_rs/tree/main/GoingDeeper/GD1516)  
<br/>

### ğŸ”  Mini-BERT Model Compression | Sep 2025  
- Investigated methods for **compressing large-scale NLP models** to enable efficient on-device inference.  
- Implemented **knowledge distillation** from BERT to a compact student model, reducing model size while retaining accuracy.  
- Applied **parameter reduction techniques** (e.g., pruning and low-rank factorization) to further optimize resource usage.  
- Conducted **benchmarks on text classification tasks**, analyzing the trade-offs between computational efficiency and predictive performance.  
- Gained insights into the practical deployment of **lightweight language models** in resource-constrained environments.   
- [ğŸ”— GitHub Repository](https://github.com/JeongMinIsBest/AIFFEL_quest_rs/tree/main/GoingDeeper/GD1314)
- [ğŸ“„ View Full Report (PDF)](/files/Width Matters Efficient Scaling of Compact BERT Models.pdf)  
<br/>

### ğŸ¤– Classical Machine Learning and DL Fundamentals | Aug 2025
- Completed an introductory project to **build foundational skills in machine learning and deep learning**.  
- Implemented core ML algorithms (**SVM, Random Forest, Logistic Regression**) on structured datasets, practicing feature engineering and model selection.  
- Designed and trained **basic neural networks** using TensorFlow and PyTorch to compare performance with classical ML approaches.  
- Evaluated models through **cross-validation and performance metrics**, gaining a solid understanding of trade-offs between classical ML and DL methods.  
- [ğŸ”— GitHub Repository](https://github.com/JeongMinIsBest/AIFFEL_quest_rs/tree/main/GoingDeeper/GD0304)  
<br/>

### ğŸ—¨ï¸ NLP Pipeline and Korean Chatbot | Aug 2025  
- Developed a Korean **dialogue system prototype** inspired by the Cornell Movie Dialogs dataset, aiming to explore open-domain chatbot capabilities.  
- Built preprocessing pipelines, including **SentencePiece tokenization, subword vocabulary construction, and text cleaning**.  
- Implemented and trained baseline models (**Seq2Seq and Transformer-based architectures**) for response generation.  
- Conducted evaluation using **BLEU and BERTScore**, and analyzed the effects of different decoding strategies (greedy, beam search, sampling).  
- [ğŸ”— GitHub Repository](https://github.com/JeongMinIsBest/AIFFEL_quest_rs/tree/main/GoingDeeper/GD0910)  
<br/>

### ğŸŒ³ ESG-based Credit Scoring Model for Small Businesses | Jun 2025 - Aug 2025
- Developed an **ESG-integrated credit scoring model** to improve financial accessibility for small businesses in Korea.  
- Incorporated **non-financial ESG indicators** (energy savings, social contributions, privacy protection) alongside traditional credit factors.  
- Applied **XGBoost and CatBoost** for predictive modeling, achieving higher fairness and interpretability.  
- Proposed policy implications for regional banks to enhance financial inclusion.  
- [ğŸ“„ View Full Report (PDF)](/files/MyResearchPoster.pdf)
<br/>

### ğŸ¦ Shinhan Big Data Hackathon: ESG Financial Product Design | Oct 2024 - Nov 2024  
- Defined a **Green Consumption Index** using **PCA and clustering techniques** on consumption data.  
- Identified customer segments based on ESG consumption behaviors.  
- Designed a new **green savings account product**, linking financial incentives to sustainable consumption.  
- Proposed marketing and policy strategies to attract **young customers (20sâ€“30s)** to ESG products.  
- [ğŸ”— Notion Page](https://www.notion.so/Green-Consumption-Savings-Account-ESG-Financial-Product-Proposal-1d1fb4f8761581369fb9c56899e5494a?source=copy_link)
<br/>

### ğŸ“š Shakespeare Text Mining: Tragedies vs. Comedies | Dec 2023
- Performed **computational text analysis** on Shakespeareâ€™s tragedies and comedies to explore linguistic and thematic differences.  
- Quantified the **frequency of â€œdeathâ€ and related semantic fields**, highlighting genre-specific lexical patterns.  
- Applied **sentiment analysis** to compare emotional tones across the two genres.  
- Showcased the integration of an **English Literature background** with **NLP and Data Science techniques**, bridging the gap between humanities and computational research.  
- [ğŸ“„ View Full Report (PDF)](/files/Data_Analysis.pdf)
<br/>
<br/>

## ğŸ“‚ Research Themes  
My research contributions align with three primary themes:
  
1. **Efficient NLP and Large Language Models** â€” Developing and fine-tuning models for dialogue generation, classification, and multilingual tasks, with a focus on model compression, parameter-efficient adaptation, and deployment in low-resource environments.
  
2. **AI for Social Impact and Responsible System**s â€” Applying machine learning to domains such as ESG-based credit scoring, sustainable finance, and public-facing AI services, demonstrating how data-driven systems can support fairness, accessibility, and real-world decision-making.
  
3. **Computational Humanities and Cross-disciplinary AI** â€” Bridging linguistics, NLP, and digital humanities through projects such as Shakespeare corpus analysis and language-driven cultural exploration, showing how computational approaches can extend traditional humanities research.
  
Collectively, these themes reflect my goal of building efficient, human-centered, and socially meaningful NLP systems.
<br/>
<br/>
